#'
## ---- echo=TRUE, results="hide", message=FALSE, warning=FALSE------------
model_3_results <- as.data.frame(summary(model_3)$conf.int)
model_3_results <- model_3_results[,-2] #Remove column 2 [exp(-coef)]
model_3_results <- cbind(model_3_results,summary(model_3)$coefficients) #Add the coefficients info which has the p-value
model_3_results <- model_3_results[,-c(4,5,6,7)] #Remove columns 4, 5, 6, and 7 [coef, exp(coef), se(coef), and z]
colnames(model_3_results) <- c("HR", "CI (Lower .95)", "CI (Upper .95)", "p-value")
model_3_results <- tibble::rownames_to_column(model_3_results, 'Covariate')
#' ### Model 4
#' LNR (as a categorical variable, 'LNR_categorical'), age, tumor stage T, histology, size
#'
## ---- echo=TRUE, results="show", message=FALSE, warning=FALSE------------
#Trying with different cutoffs
botdata[,'LNR_categorical'] <-ifelse(botdata$'Lymph_node_ratio'<13, 1, 2)
# Make sure it is a factor (categorical variable)
botdata$LNR_categorical <- as.factor(botdata$LNR_categorical)
# Switch column names to the display names
botdata <- setNames(botdata, display_colnames)
covariates <- c("`Age (y)`", "`T Stage`", "`Histology`", "`Tumor size (cm)`", "`Lymph node ratio`")
covariates2 <- as.character(display_names.df$original_name[match(gsub("`","",covariates),display_names.df$display_name)])
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
x <- as.formula(paste("Surv(`Survival months`, DOD) ~ ",paste(covariates2, collapse="+"),sep = "")) # formula for coxph
model_4 <- coxph(x,  data =  botdata)
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
summary(model_4)
# Make vector with the appropriate names
#'
#' Let's extract the results and format them how we want them:
#'
## ---- echo=TRUE, results="hide", message=FALSE, warning=FALSE------------
model_4_results <- as.data.frame(summary(model_4)$conf.int)
model_4_results <- model_4_results[,-2] #Remove column 2 [exp(-coef)]
model_4_results <- cbind(model_4_results,summary(model_4)$coefficients) #Add the coefficients info which has the p-value
model_4_results <- model_4_results[,-c(4,5,6,7)] #Remove columns 4, 5, 6, and 7 [coef, exp(coef), se(coef), and z]
colnames(model_4_results) <- c("HR", "CI (Lower .95)", "CI (Upper .95)", "p-value")
model_4_results <- tibble::rownames_to_column(model_4_results, 'Covariate')
#!!!!! https://stackoverflow.com/questions/45502141/include-reference-levels-in-print-of-coefficients-from-coxph
library(tidyverse)
library(broom)
library(survival)
function1 <- function( model_object ) {
#l1 <- model_object$xlevels
#output_list <- list()
#for (i in 1:length(l1) ) {
#output_list[[i]] <-  paste0( names(l1[i]),  as.character( unlist( l1[i] )  )  )
#}
#unlist( output_list)
}
#input_to_function <- model_4
#function_output <- function1(input_to_function)
#values <- tidy(input_to_function, exponentiate = TRUE )
#covariate_list2 <- c(function_output,
#names( attr( input_to_function$terms, "dataClasses" )[ attr( #input_to_function$terms, "dataClasses" )  == "numeric"  ]  )
#)
#covariate_list3 <- c(function_output,
#names( attr( input_to_function$terms, "dataClasses" )
#))
#covariate_df <- data.frame( term = covariate_list3)
#left_join( covariate_df, values, "term" )
# Switch column names to the display names
botdata <- setNames(botdata, display_colnames)
library(Publish)
# Grab the first level of each covariates, since we set it up that the 1st level is the reference level
refs <- as.character() # Set up an empty character vector called 'refs' to store the info
for (i in 1:length(gsub("`","",covariates))) {
refs[i]<-levels(botdata[,gsub("`","",covariates)[i]])[1]
}
factorlevels <- list() # Set up an empty character vector called 'refs' to store the info
for (i in 1:length(gsub("`","",covariates))) {
factorlevels[[i]]<-levels(botdata[,gsub("`","",covariates[i])])
}
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
a<-publish(model_4, handler="sprintf",digits=c(2,2),pValue.stars=TRUE)
final.df <- a$regressionTable
# Add display names
final.df$Variable <- as.character(display_names.df$display_name[match(final.df$Variable, display_names.df$original_name)])
# Convert NAs that were just added to blanks
final.df$Variable[is.na(final.df$Variable)] <- ""
# Format the same way as Table 1, with an "empty"" header row
# Now add a column to the 'test' df and put a 2 or 1 depending on how many times it should be repeated
final.df$vartype <- as.character(vartype.df$type[match(final.df$Variable,rownames(vartype.df))])
# Convert NAs that were just added to blanks
final.df$vartype[is.na(final.df$vartype)] <- ""
final.df$num_of_rows <- as.character(ifelse(final.df$vartype=="factor", 2, 1))
# Convert NAs that were just added to blanks
final.df$num_of_rows[is.na(final.df$num_of_rows)] <- 1
final.df[] <- lapply(final.df, as.character)
final.df[,2] <- gsub("<", "<", final.df[,2])
# Duplicate rows as needed (only for rows that say "factor" in the vartype column)
model4.df <- final.df[rep(rownames(final.df), final.df$num_of_rows),]
model4.df <- tibble::rownames_to_column(model4.df, "temp_rowname")
rows_to_erase_col_1 <- model4.df$temp_rowname[which(grepl("\\.1", model4.df$temp_rowname))] # Grab rows with rowname ending in ".1" - these will have column 1 value erased (note the \\ is for making it recognize the .)
rows_to_erase_cols_2_3_4 <- model4.df$temp_rowname[which(grepl("\\.1", model4.df$temp_rowname))-1] # Grab rows above those ending in ".1" - these will have column 2-4 values erased
# Erase cells as appropriate
model4.df[match(rows_to_erase_col_1,model4.df$temp_rowname),"Variable"] <- ""
model4.df[match(rows_to_erase_cols_2_3_4,model4.df$temp_rowname),3:4] <- ""
model4.df <- model4.df[,-c(1,9)]
model4.df$Variable[model4.df$Variable==""] <- model4.df$Units[model4.df$Variable==""]
model4.df <- model4.df[,-2]
table_3_rows_to_indent <- model4.df[,2] %>% { which(. != "") }
# Don't indent rows labeled as "integer" or "numeric" (continuous variables)
# NEED TO ADD THIS FUNCTIONALITY TO THE TABLE 1 SECTION AS A SAFEGUARD
y <- match(model4.df[,6] %>% { which(. == "numeric") },table_3_rows_to_indent)
z <- match(model4.df[,6] %>% { which(. == "integer") },table_3_rows_to_indent)
if (length(y)>0) {
table_3_rows_to_indent <- table_3_rows_to_indent[-y]
}
if (length(z)>0) {
table_3_rows_to_indent <- table_3_rows_to_indent[-z]
}
model4.df <- model4.df[,-6] # Remove vartype placeholder column
model4.df$HazardRatio <- gsub("Ref", 1, model4.df$HazardRatio)
model4.df$CI.95 <- gsub("\\[","\\(",model4.df$CI.95)
model4.df$CI.95 <- gsub("\\;","\\–",model4.df$CI.95)
model4.df$CI.95 <- gsub("\\]","\\)",model4.df$CI.95)
model4.df$HazardRatio <- paste0(model4.df$HazardRatio," ",model4.df$CI.95)
model4.df <- model4.df[,-3]
names(model4.df) <- c("Characteristic", "Hazard Ratio (95% CI)", "P-value","signif")
##model4.df[,1] <- trimws(model4.df[,1])
##model4.df[,2] <- trimws(model4.df[,2])
##model4.df[,3] <- trimws(model4.df[,3])
##model4.df[,4] <- trimws(model4.df[,4])
library(knitr)
library(kableExtra)
kable(model4.df, "html", caption = "Cause-Specific Survival", booktabs = T, row.names = FALSE) %>%
kable_styling() %>%
add_indent(table_3_rows_to_indent)
#model4.df[,2]<-gsub("5","5",model4.df[,2])
#model4.df[,2]<-gsub("0","0",model4.df[,2])
model4.df[2,1]<-"test"
model4.df[17,1]<-"test"
model4.df[2,1]<-"\u003C50"
model4.df[17,1]<-"0"
kable(model4.df, "latex", caption = "Cause-Specific Survival", booktabs = T, row.names = FALSE) %>%
kable_styling() %>%
add_indent(table_3_rows_to_indent) # This line seems to be causing weird spacing issues in the PDF table output... in combination with row.names = FALSE.... when you set row names to TRUE the row names get indented correctly (but we don't want row names...)... Specifically row 17 (which starts with '0'), is causing the problem. If I try to indent that row it's an issue with '<5    0' (row 2) + row 17 not indenting. Any other rows can be indented without a problem.
# Also, it's somehow not an issue for the html version. That works totally fine. It's an issue with Latex/KableExtra.
# Also, it seems to become an issue only after deleting or altering the Unit column (line 1082)
#test.df <- data.frame(matrix(NA, nrow = 20, ncol = 3))
#test.df[,1] <- c(1:20)
#test.df[,2] <- 3
#test.df[,3] <- 4
#kable(test.df, "latex", caption = "My Caption", booktabs = T, row.names = FALSE) %>%
#  kable_styling() %>%
#  add_indent(table_3_rows_to_indent)
# STARGAZER - look into this
# library(stargazer)
#'
#' ## Multivariable Analysis
#'
## ---- echo=TRUE, results="show", message=FALSE, warning=FALSE------------
library(survival)
# Model 1: Dichotomize by LN+/LN-, age, tumor stage T, histology, size
model_1 <- coxph(Surv(`Survival months`, DOD) ~ Age_di_U50 + T_stage + Histology + Size_5_10 + Node_pos_neg, data =  botdata)
# Model 2: Multiple Mets? (0, 1, 2 = 2 or more), age, tumor stage T, histology, size
model_2 <- coxph(Surv(`Survival months`, DOD) ~ Age_di_U50 + T_stage + Histology + Size_5_10 + Multiple_nodes, data =  botdata)
# Model 3: LNR (as a continuous variable, 'Lymph_node_ratio'), age, tumor stage T, histology, size
model_3 <- coxph(Surv(`Survival months`, DOD) ~ Age_di_U50 + T_stage + Histology + Size_5_10 + Lymph_node_ratio,  data =  botdata)
# Model 4a: LNR (as a categorical variable, 'LNR_categorical'), age, tumor stage T, histology, size
#Trying with different cutoffs
botdata[,'LNR_categorical'] <-ifelse(botdata$'Lymph_node_ratio'==0,0,ifelse(botdata$'Lymph_node_ratio'<13, 1, 2))
# Make sure it is a factor (categorical variable)
botdata$LNR_categorical <- as.factor(botdata$LNR_categorical)
# Rename 0/1/2 to "0%", "0% < LNR < 13%", and "LNR ≥ 13%"
botdata$LNR_categorical <- gsub(0,"0%",botdata$LNR_categorical)
botdata$LNR_categorical <- gsub(1,"0% < LNR < 13%",botdata$LNR_categorical)
botdata$LNR_categorical <- gsub(2,"LNR ≥ 13%",botdata$LNR_categorical)
# Switch column names to the display names
botdata <- setNames(botdata, display_colnames)
covariates <- c("`Age (y)`", "`T Stage`", "`Histology`", "`Tumor size (cm)`", "`Lymph node ratio`")
covariates2 <- as.character(display_names.df$original_name[match(gsub("`","",covariates),display_names.df$display_name)])
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
x <- as.formula(paste("Surv(`Survival months`, DOD) ~ ",paste(covariates2, collapse="+"),sep = "")) # formula for coxph
model_4a <- coxph(x,  data =  botdata)
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
# Model 4b: LNR (as a categorical variable, 'LNR_categorical'), age, tumor stage T, histology, size
#Trying with different cutoffs
botdata[,'LNR_categorical'] <-ifelse(botdata$'Lymph_node_ratio'<13, "< 13%", "≥ 13%")
# Make sure it is a factor (categorical variable)
botdata$LNR_categorical <- as.factor(botdata$LNR_categorical)
# Switch column names to the display names
botdata <- setNames(botdata, display_colnames)
covariates <- c("`Age (y)`", "`T Stage`", "`Histology`", "`Tumor size (cm)`", "`Lymph node ratio`")
covariates2 <- as.character(display_names.df$original_name[match(gsub("`","",covariates),display_names.df$display_name)])
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
x <- as.formula(paste("Surv(`Survival months`, DOD) ~ ",paste(covariates2, collapse="+"),sep = "")) # formula for coxph
model_4b <- coxph(x,  data =  botdata)
# Toggle back to the original column names
botdata <- setNames(botdata, original_colnames)
#'
#' Write a function to format tables exactly how you want them to look.
#'
## ---- echo=TRUE, results="show", message=FALSE, warning=FALSE------------
library(Publish)
library(officer)
library(flextable)
library(magrittr)
# Note: "x" is the coxph model (model_1, model_2, etc.)
reformat_table <- function(x) {
x <- publish(x, handler="sprintf",digits=c(3),pvalue.digits=1,pvalue.eps=0.001,pValue.stars=TRUE)$regressionTable
# Add display names
x$Variable <- as.character(display_names.df$display_name[match(x$Variable, display_names.df$original_name)])
# Replace 'Ref' with 1
x$HazardRatio <- gsub("Ref", "1", x$HazardRatio)
x$CI.95 <- gsub("\\[","\\(",x$CI.95)
x$CI.95 <- gsub("\\;","\\–",x$CI.95)
x$CI.95 <- gsub("\\]","\\)",x$CI.95)
x$HazardRatio <- paste0(x$HazardRatio," ",x$CI.95)
x <- x[,-4]
# Fix column names (for some reason they all need to be one word w/ no spaces or else they won't print to Word Doc correctly using flextable)
names(x) <- c("Characteristic", "Units", "HR", "pvalue","psignif")
x$Characteristic[is.na(x$Characteristic)] <- "" # Convert NAs to blanks
x$vartype <- as.character(vartype.df$type[match(x$Characteristic,rownames(vartype.df))])
# Convert NAs that were just added to blanks
x$vartype[is.na(x$vartype)] <- ""
x$num_of_rows <- as.character(ifelse(x$vartype=="factor", 2, 1))
# Convert NAs that were just added to blanks
x$num_of_rows[is.na(x$num_of_rows)] <- 1
x[] <- lapply(x, as.character)
x[,2] <- gsub("<", "<", x[,2])
# Duplicate rows as needed (only for rows that say "factor" in the vartype column)
x <- x[rep(rownames(x), x$num_of_rows),]
x <- tibble::rownames_to_column(x, "temp_rowname")
rows_to_erase_col_1 <- x$temp_rowname[which(grepl("\\.1", x$temp_rowname))] # Grab rows with rowname ending in ".1" - these will have column 1 value erased (note the \\ is for making it recognize the .)
rows_to_erase_cols_2_3_4 <- x$temp_rowname[which(grepl("\\.1", x$temp_rowname))-1] # Grab rows above those ending in ".1" - these will have column 2-4 values erased
# Erase cells as appropriate
x[match(rows_to_erase_col_1,x$temp_rowname),"Characteristic"] <- ""
x[match(rows_to_erase_cols_2_3_4,x$temp_rowname),3:4] <- ""
x <- x[,-c(1,8)]
x$Characteristic[x$Characteristic==""] <- x$Units[x$Characteristic==""]
# Indent rows
rows_to_indent <- x[,2] %>% { which(. != "") }
# Don't indent for continuous variables (numeric or integer)
x.num<-match(x[,"vartype"] %>% { which(. == "numeric") },rows_to_indent)
#if( is.na(match(x[,"vartype"] %>% { which(. == "numeric") },rows_to_indent))) {
#  x.num <- integer()
#}
x.num<-ifelse(is.na(match(x[,"vartype"] %>% { which(. == "integer") },rows_to_indent)),x.num <- integer(),match(x[,"vartype"] %>% { which(. == "integer") },rows_to_indent))
x.int <- match(x[,"vartype"] %>% { which(. == "integer") },rows_to_indent)
ifelse(is.na(match(x[,"vartype"] %>% { which(. == "integer") },rows_to_indent)),x.int <- integer(),match(x[,"vartype"] %>% { which(. == "integer") },rows_to_indent))
if (length(x.num)>0) {
rows_to_indent <- rows_to_indent[-x.num]
}
if (length(x.int)>0) {
rows_to_indent <- rows_to_indent[-x.int]
}
# Remove the empty "Units" column and the "vartype" column
x <- x[,-c(2,6)]
# Rename columns and customize alignment
y<-flextable(data = x, col_keys = make.names(names(x))) %>%
theme_booktabs()
y<-display(y, col_key = "HR",
part = "header",
pattern = "HR (95% CI)")
y<-display(y, col_key = "pvalue",
part = "header",
pattern = "P-value")
y<-display(y, col_key = "psignif",
part = "header",
pattern = " ")
y <- bold(y, part = "header")
y<-align(y, align = "center", j=1, part = "header")
y<-align(y, align = "left", j=1, part = "body")
y<-align(y, align = "center", j=2:4, part = "all")
# Add padding to indent specific rows in the first column
y<-padding(y, i = rows_to_indent, j=1, padding.left = 24, part = "body")
y<-autofit(y)
return(y)
}
# https://davidgohel.github.io/flextable/articles/format.html - Notes for formatting flextable
# Apply function to models 1-4
model1.ft <- reformat_table(model_1)
model2.ft <- reformat_table(model_2)
model3.ft <- reformat_table(model_3)
model4a.ft <- reformat_table(model_4a)
model4b.ft <- reformat_table(model_4b)
# Create flextable for Table 1 (patient demographics)
names(test2) <- c("Characteristic", "value")
table1.ft <- flextable(data = test2, col_keys = make.names(names(test2))) %>%
theme_booktabs()
table1.ft<-display(table1.ft, col_key = "value",
part = "header",
pattern = "n = 1524")
table1.ft <- bold(table1.ft, part = "header")
table1.ft<-align(table1.ft, align = "center", part = "header")
table1.ft<-align(table1.ft, align = "center", j=2, part = "all")
table1.ft<-align(table1.ft, align = "left", j=1, part = "body")
# Add padding to indent specific rows in the first column
table1.ft<-padding(table1.ft, i = table_1_rows_to_indent, j=1, padding.left = 24, part = "body")
table1.ft<-autofit(table1.ft)
# Save tables to a Word document
read_docx() %>%
body_add_par("Table 1", style = "Normal") %>%
body_add_flextable(table1.ft) %>%
body_add_break() %>%
body_add_par("Model 1", style = "Normal") %>%
body_add_flextable(model1.ft) %>%
body_add_break() %>%
body_add_par("Model 2", style = "Normal") %>%
body_add_flextable(model2.ft) %>%
body_add_break() %>%
body_add_par("Model 3", style = "Normal") %>%
body_add_flextable(model3.ft) %>%
body_add_break() %>%
body_add_par("Model 4a", style = "Normal") %>%
body_add_flextable(model4a.ft) %>%
body_add_break() %>%
body_add_par("Model 4b", style = "Normal") %>%
body_add_flextable(model4b.ft) %>%
print(target = "Multivariable Analysis.docx")
#library(sjPlot)
#tab_df(model1.df)
#'
#' ## Save Results
#' Now let's save the results as an Excel file.
#'
## ---- echo=TRUE, results="hide", message=FALSE, warning=FALSE------------
# Save the results of the univariate analysis to an Excel file.
#write.xlsx(model_1_results, file = "Multivariable Analysis.xlsx", col.names = TRUE, row.names = FALSE, sheetName="Model 1", append=FALSE)
#write.xlsx(model_2_results, file = "Multivariable Analysis.xlsx", col.names = TRUE, row.names = FALSE, sheetName="Model 2", append=TRUE)
#write.xlsx(model_3_results, file = "Multivariable Analysis.xlsx", col.names = TRUE, row.names = FALSE, sheetName="Model 3", append=TRUE)
#write.xlsx(model_4_results, file = "Multivariable Analysis.xlsx", col.names = TRUE, row.names = FALSE, sheetName="Model 4", append=TRUE)
#'
#' I reformatted the info into 1 sheet and nicely formatted in Excel, and deleted the z column (not sure why we need it). It would be nice to program R to automatically format it the way I did in Excel where tehre's an extra row to show the baseline comparison with HR = 1. Should be doable to just put all of the results into a data frame and add rows accordingly.
#'
#'
#' ## Table 4
#' <b>Risk factors for lymph node metastasis</b>
#'
#' Characteristic  | Node-negative | Node-positive | p-value
#'
#' "Percent expressions are per row. Student t-test, Mann-Whitney U test, or chis-square test for P-values."
#'
#' Not sure exactly what we will change this to - probably stratify by LNR.
#'
#' ## Figure 2
#' <b>Cause-specific survival based on surgical staging procedure and age</b>
#'
#' Same as Figure 1 but stratified by age (under 50 and over 50)
#'
#' "Log-rank test for P-values. Survival curves for women with stage T1a borderline ovarian tumors are shown for A) age younger than 50 years and B) age 50 years or older."
#'
#' ## Supplementary Data
#'
#' This project is modeled after [Dr. Matsuo's paper](/Users/david/Gyn Onc Research/Matsuo Early Stage BOT Paper.pdf){target="_blank"} on early stage BOTs. The [supplemental file](/Users/david/Gyn Onc Research/Matsuo Early Stage BOT Paper Supplement.docx){target="_blank"} from that paper contains the following tables/figures:
#'
#' ### Figure S1
#' <b>Cause-specific survival based on lymph node status</b>
#'
#' y-axis: Cause-specific survival (%)
#' x-axis: Time (years)
#'
#' Table directly underneath plot showing # of cases at each time point (different columns in the table lined up w/ time points), stratified by group (different rows in the table)
#'
#' "Log-rank test for Ptrend-value."
#'
#' ### Table S1
#' <b>Characteristics based on tumor stage</b>
#'
#' Table 1 but stratified by tumor stage; includes p-values.
#' Note that everything here is categorical-no continuous variables.
#'
#' "Percentage expressions are per row. Chi-square test, one-way ANOVA test, or Kruskal-Wallis test for P-values."
#'
#' ### Table S2
#' <b>Characteristics per histology type</b>
#'
#' Table 1 but stratified by histology type (serous vs. mucinous).
#'
#' "Percentage expressions are per row. Chi-square test, Student t test, or Mann-Whitney U test for P-values."
#'
#' ### Table S3
#' <b>Cause-specific survival for stage T1 tumors</b>
#'
#' Table 1 but shows % of each category who survived at 10-yrs and 20-yrs, w/ HR and p-value.
#' <b>We might need to make one of these for each tumor stage, plus one including all tumor stages.</b>
#'
#' "A Cox proportional hazard regression model for multivariable analysis. All the covariates in the table were entered in the final model. Significant P-values are emboldened. VIF <2.0 for procedure type and nodal metastasis with absence of multicollinearity."
#'
#' ### Table S4
#' <b>Risks and benefits based on type of initial surgery</b>
#'
#' Table 1 but stratified by histology type (serous vs. mucinous).
#'
#' "Percentage expressions are per row. Chi-square test, Student t test, or Mann-Whitney U test for P-values."
#'
#' <b>(Not sure if we will include this.)</b>
#'
View(botdata)
botdata[1,]
botdata[,1]
predictors <- t(botdata[,-c(1,22,23)])
dim(predictors)
as.factor(botdata$DOD)
response <- as.factor(botdata$DOD)
rf.data <- data.frame(response, predictors)
response <- t(as.factor(botdata$DOD))
response
rf.data <- data.frame(response, predictors)
str(response)
response <- as.factor(botdata$DOD)
response
str(predictors)
str(response)
response
length(response)
View(predictors)
predictors <- botdata[,-c(1,22,23)]
dim(predictors)
View(predictors)
response <- as.factor(botdata$DOD)
rf.data <- data.frame(response, predictors)
View(rf.data)
library(randomForest)
set.seed(2)
botdata.classify <- randomForest(response~., data = rf.data, ntree = 100)
View(botdata)
predictors <- botdata[,-c(1,11,22,23)]
dim(predictors)
response <- as.factor(botdata$DOD)
rf.data <- data.frame(response, predictors)
library(randomForest)
set.seed(2)
botdata.classify <- randomForest(response~., data = rf.data, ntree = 100)
View(rf.data)
predictors <- botdata[,-c(1,11,13,14,20,21,22,23)]
dim(predictors)
#Make one column for our outcome/response variable (D)
response <- as.factor(botdata$DOD)
#Combine them into 1 data frame
rf.data <- data.frame(response, predictors)
set.seed(2)
botdata.classify <- randomForest(response~., data = rf.data, ntree = 100)
randomForest(response~., data = rf.data, ntree = 100, na.action=na.roughfix)
print(botdata.classify)
botdata.classify <- randomForest(response~., data = rf.data, ntree = 100, na.action=na.roughfix)
print(botdata.classify)
?randomForest
round(importance(botdata.classify), 2)
MDSplot(botdata.classify, botdata$Lymph_node_ratio)
MDSplot(botdata.classify, botdata$LNR_categorical)
botdata.rf <- randomForest(response~., data = rf.data, ntree = 100, na.action=na.roughfix)
print(botdata.rf)
round(importance(botdata.classify), 2)
round(importance(botdata.rf), 2)
botdata.mds <- cmdscale(1 - botdata.rf$proximity, eig=TRUE)
cmdscale(1 - botdata.rf$proximity, eig=TRUE)
botdata.rf
botdata.rf$proximity
imp <- importance(botdata.rf)
imp <- data.frame(predictors = rownames(imp), imp)
imp.sort <- arrange(imp, desc(MeanDecreaseGini))
imp.sort$predictors <- factor(imp.sort$predictors, levels = imp.sort$predictors)
imp.20 <- imp.sort[1:20, ]
imp.sort
arrange(round(importance(botdata.rf), 2),desc(MeanDecreaseGini))
predictor.importance <- round(importance(botdata.rf), 2)
predictor.importance <- arrange(predictor.importance, desc(MeanDecreaseGini))
predictor.importance <- as.data.frame(round(importance(botdata.rf), 2))
predictor.importance <- arrange(predictor.importance, desc(MeanDecreaseGini))
predictor.importance
View(predictor.importance)
predictor.importance <- data.frame(predictors = rownames(predictor.importance), predictor.importance)
predictor.importance
predictor.importance <- round(importance(botdata.rf), 2)
predictor.importance
rownames(predictor.importance)
data.frame(predictors = rownames(predictor.importance), predictor.importance)
predictor.importance <- data.frame(predictors = rownames(predictor.importance), predictor.importance)
predictor.importance
predictor.importance <- arrange(predictor.importance, desc(MeanDecreaseGini))
predictor.importance$predictors <- factor(predictor.importance$predictors, levels = predictor.importance$predictors)
predictor.importance
library(ggplot2)
ggplot(predictor.importance, aes(x = predictors, y = MeanDecreaseGini)) +
geom_bar(stat = "identity", fill = "indianred") +
coord_flip() +
ggtitle("Most important features for predicting DOD")
botdata <- setNames(botdata, display_colnames)
predictors <- botdata[,-c(1,11,13,14,20,21,22,23)]
dim(predictors)
response <- as.factor(botdata$DOD)
rf.data <- data.frame(response, predictors)
library(randomForest)
set.seed(2)
botdata.rf <- randomForest(response~., data = rf.data, ntree = 100, na.action=na.roughfix)
print(botdata.rf)
round(importance(botdata.rf), 2)
predictor.importance <- round(importance(botdata.rf), 2)
predictor.importance <- data.frame(predictors = rownames(predictor.importance), predictor.importance)
predictor.importance <- arrange(predictor.importance, desc(MeanDecreaseGini))
predictor.importance$predictors <- factor(predictor.importance$predictors, levels = predictor.importance$predictors)
predictor.importance
library(ggplot2)
ggplot(predictor.importance, aes(x = predictors, y = MeanDecreaseGini)) +
geom_bar(stat = "identity", fill = "indianred") +
coord_flip() +
ggtitle("Most important features for predicting DOD")
<symbol id="email" viewBox="0 0 512 512">
<path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></symbol>
setwd("/Users/david/djnusbaum.github.io/")
rmarkdown::render_site()
setwd("/Users/david/github/djnusbaum.github.io/")
rmarkdown::render_site()
setwd("/Users/david/github/djnusbaum.github.io/")
rmarkdown::render_site()
